# stock_news_st
# æ”¹å–„:
# - ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤ºï¼†ãƒ•ã‚£ãƒ«ã‚¿
# - å„è¡Œã«ã€Œã‚³ãƒ”ãƒ¼ã€ã€ŒæŒ¿å…¥ã€ãƒœã‚¿ãƒ³ï¼ˆã‚³ãƒ”ãƒ¼ã¯å®‰å®šåŒ–ã€æŒ¿å…¥ã¯å…¥åŠ›æ¬„ã¸å³åæ˜ ï¼‰
# - ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã¯å®‰å…¨ãªãƒ•ãƒ©ã‚°æ–¹å¼ã§ã‚¨ãƒ©ãƒ¼å›é¿
# - å…¥åŠ›æ¬„ã¨ã€Œã‚¯ãƒªã‚¢ã€ãƒœã‚¿ãƒ³ã®ã‚ºãƒ¬è§£æ¶ˆï¼ˆå…±é€šãƒ©ãƒ™ãƒ«ï¼‹ç¸¦ä¸­å¤®æƒãˆï¼‰
# - ã€ŒæŒ¿å…¥ã€ãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’ â€œ<ticker> ã‚’æŒ¿å…¥â€ ã«å‹•çš„åŒ–
# - ã€ä»Šå›ã€‘é…å½“TTMã®å …ç‰¢åŒ–ï¼šTTM=400æ—¥è¨±å®¹ + ç›´è¿‘æœ€å¤§2å›åˆè¨ˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

import io
import re
import unicodedata
from pathlib import Path
from html import escape
import urllib.parse

import pandas as pd
import streamlit as st
import streamlit.components.v1 as components
import yfinance as yf
import feedparser  # type: ignore
import altair as alt


# ========= ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========
def _norm(s: str) -> str:
    return unicodedata.normalize("NFKC", str(s)).strip()

def _has_japanese(s: str) -> bool:
    return bool(re.search(r"[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥ï½¦-ï¾Ÿãƒ»ï½°ãƒ¼]", s))


DATA_DIR = Path("data")
ALIAS_PATH = DATA_DIR / "aliases.xlsx"

def _ensure_dir(p: Path):
    p.parent.mkdir(parents=True, exist_ok=True)

def _validate_alias_df(df: pd.DataFrame) -> pd.DataFrame:
    # æ—¥æœ¬èª/è‹±èªãƒ˜ãƒƒãƒ€ãƒ¼ä¸¡å¯¾å¿œ
    rename_map = {
        "Ticker": "ticker", "Alias": "alias",
        "ticker": "ticker", "alias": "alias",
        "ã‚³ãƒ¼ãƒ‰": "ticker", "éŠ˜æŸ„å": "alias",
    }
    df = df.rename(columns=rename_map)
    if not {"ticker", "alias"}.issubset(df.columns):
        raise ValueError("å¿…è¦åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚'ã‚³ãƒ¼ãƒ‰/éŠ˜æŸ„å' ã¾ãŸã¯ 'Ticker/Alias' ã‚’ç”¨æ„ã—ã¦ãã ã•ã„ã€‚")
    df = df[["ticker", "alias"]].copy()
    df["ticker"] = df["ticker"].map(_norm)
    df["alias"]  = df["alias"].map(_norm)
    df = df.dropna(subset=["ticker", "alias"])
    return df

@st.cache_data(show_spinner=False)
def load_alias_from_disk() -> pd.DataFrame:
    if ALIAS_PATH.exists():
        if ALIAS_PATH.suffix.lower() in (".xlsx", ".xls"):
            df = pd.read_excel(ALIAS_PATH)
        elif ALIAS_PATH.suffix.lower() in (".csv", ".txt"):
            df = pd.read_csv(ALIAS_PATH)
        else:
            return pd.DataFrame(columns=["ticker", "alias"])
        return _validate_alias_df(df)
    return pd.DataFrame(columns=["ticker", "alias"])

def save_uploaded_alias(uploaded_file) -> str:
    fname = uploaded_file.name.lower()
    if fname.endswith((".xlsx", ".xls")):
        df = pd.read_excel(uploaded_file); ext = ".xlsx"
    elif fname.endswith((".csv", ".txt")):
        df = pd.read_csv(uploaded_file); ext = ".csv"
    else:
        raise ValueError("å¯¾å¿œæ‹¡å¼µå­ã¯ .xlsx/.xls/.csv/.txt ã§ã™ã€‚")

    df = _validate_alias_df(df)
    _ensure_dir(ALIAS_PATH)
    target = ALIAS_PATH.with_suffix(ext)
    tmp = target.with_suffix(ext + ".tmp")

    if ext == ".xlsx":
        with pd.ExcelWriter(tmp, engine="xlsxwriter") as w:
            df.to_excel(w, index=False)
    else:
        df.to_csv(tmp, index=False, encoding="utf-8-sig")

    if target.exists():
        target.unlink()
    tmp.rename(target)

    # æ—§å½¢å¼ã®æƒé™¤
    for other in (".xlsx", ".xls", ".csv", ".txt"):
        p = ALIAS_PATH.with_suffix(other)
        if p.exists() and p != target:
            try: p.unlink()
            except Exception: pass

    load_alias_from_disk.clear()
    return str(target)

def download_current_alias_button(df: pd.DataFrame):
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as w:
        (df if not df.empty else pd.DataFrame(columns=["ticker","alias"])).to_excel(w, index=False)
    st.download_button(
        "ç¾åœ¨ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆxlsxï¼‰",
        data=buf.getvalue(), file_name="aliases.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True,
    )

# ---- ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ï¼šå®‰å®šç‰ˆï¼ˆiframeå†…ã§navigator.clipboardâ†’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ ----
def copy_button(text: str, label: str, key: str):
    safe_text  = escape(text).replace("'", "&#39;")
    safe_label = escape(label)
    html = f"""
    <button id="{key}" style="
        padding:6px 10px;border-radius:8px;border:1px solid #555;
        background:#1f6feb;color:#fff;cursor:pointer">
        {safe_label}
    </button>
    <script>
      (function(){{
        const btn = document.getElementById("{key}");
        if (!btn) return;
        btn.addEventListener("click", async () => {{
          const val = "{safe_text}";
          async function modernCopy() {{
            try {{
              await navigator.clipboard.writeText(val);
              return true;
            }} catch(e) {{ return false; }}
          }}
          function legacyCopy(){{
            try {{
              const ta = document.createElement('textarea');
              ta.value = val;
              ta.style.position='fixed';
              ta.style.left='-9999px';
              document.body.appendChild(ta);
              ta.select();
              document.execCommand('copy');
              document.body.removeChild(ta);
              return true;
            }} catch(e) {{ return false; }}
          }}
          const ok = (navigator.clipboard && await modernCopy()) || legacyCopy();
          const prev = btn.innerText;
          btn.innerText = ok ? "ã‚³ãƒ”ãƒ¼æ¸ˆ" : "ã‚³ãƒ”ãƒ¼å¤±æ•—";
          setTimeout(()=>{{ btn.innerText = prev; }}, 1000);
        }});
      }})();
    </script>
    """
    components.html(html, height=42)

# ========= ã‚¿ã‚¤ãƒˆãƒ«åï¼ˆæ—¥æœ¬èªå„ªå…ˆï¼‰ =========
def display_name_for(code: str, alias_df: pd.DataFrame | None, info: dict | None) -> str:
    code = _norm(code)
    if alias_df is not None and not alias_df.empty:
        cand = alias_df.loc[alias_df["ticker"] == code, "alias"].tolist()
        jp = [a for a in cand if _has_japanese(a)]
        if jp: return max(jp, key=len)
    if info:
        for k in ("longName","shortName"):
            v = info.get(k)
            if v: return str(v)
    return code

# ========= ãƒ‹ãƒ¥ãƒ¼ã‚¹ =========
def _aliases_for(code: str, alias_df: pd.DataFrame | None = None):
    code = _norm(code)
    aliases = {code, code.replace(".T","")}
    info = {}
    try:
        t = yf.Ticker(code)
        try: info = t.get_info()
        except Exception: pass
        for k in ("longName","shortName"):
            v = info.get(k)
            if v: aliases.add(_norm(v))
    except Exception:
        pass
    if alias_df is not None and not alias_df.empty:
        extra = alias_df.loc[alias_df["ticker"] == code, "alias"].tolist()
        for a in extra:
            if a: aliases.add(_norm(a))
    manual = {"7611.T": ["ãƒã‚¤ãƒ‡ã‚¤æ—¥é«˜","æ—¥é«˜å±‹"], "5020.T": ["ï¼¥ï¼®ï¼¥ï¼¯ï¼³","ENEOS"]}
    for v in manual.get(code, []):
        aliases.add(_norm(v))
    return [a for a in aliases if a]

def _score_title(title: str, terms: list[str], code: str) -> int:
    t = _norm(title).lower(); score = 0
    for a in terms:
        a_norm = _norm(a).lower()
        if a_norm and a_norm in t: score += 2
    core = code.replace(".T","")
    if re.search(rf"(?:\(|ï¼ˆ|ã€){core}(?:\)|ï¼‰|ã€‘)", t): score += 2
    if core in t: score += 1
    return score

_EXCLUDE_TERMS = ["ã‚²ãƒ¼ãƒ ","ã‚¹ãƒ—ãƒ©","splatoon","ã‚®ã‚¢","ãƒ•ã‚§ã‚¹","OCEANS","ã‚ªãƒ¼ã‚·ãƒ£ãƒ³ã‚º"]

def fetch_news_for(code: str, alias_df: pd.DataFrame | None, days: int = 30, max_items: int = 10,
                   strict_title=True, min_score=2):
    terms = _aliases_for(code, alias_df=alias_df)
    quoted_terms = [f'"{t}"' for t in terms]
    must_have = "(æ ªä¾¡ OR æ±ºç®— OR IR OR æ¥­ç¸¾ OR å‡ºåº— OR æ—¢å­˜åº— OR æœˆæ¬¡ OR å£²ä¸Š)"
    exclude   = "-ã‚²ãƒ¼ãƒ  -ã‚¹ãƒ—ãƒ© -Splatoon -ã‚®ã‚¢ -eã‚¹ãƒãƒ¼ãƒ„ -ãƒ•ã‚§ã‚¹ -OCEANS"
    q = f'({" OR ".join(quoted_terms)}) {must_have} {exclude} when:{days}d'

    url = "https://news.google.com/rss/search?" + urllib.parse.urlencode({
        "q": q, "hl":"ja", "gl":"JP", "ceid":"JP:ja",
    })
    feed = feedparser.parse(url)

    pool = []
    for e in feed.entries[: max_items*3]:
        title = getattr(e,"title","")
        if not title: continue
        low = title.lower()
        if any(x.lower() in low for x in _EXCLUDE_TERMS): continue
        score = _score_title(title, terms, code)
        if (not strict_title) or (score >= min_score):
            pool.append({
                "title": title,
                "link": getattr(e,"link",""),
                "published": getattr(e,"published",""),
                "score": score,
            })
    pool.sort(key=lambda x: (x["score"], x.get("published","")), reverse=True)
    return pool[:max_items]

# ========= é…å½“ï¼ˆTTMå¼·åŒ–ç‰ˆï¼‰ =========
def get_dividend_info(code: str, last_close: float, ttm_days: int = 400) -> dict:
    """
    - yfinanceã®dividendsï¼ˆSeries, index=Datetimeï¼‰ã‚’å–å¾—
    - TTMã¯éå»ttm_daysï¼ˆãƒ‡ãƒ•ã‚©400æ—¥ï¼‰ã§åˆè¨ˆ
    - TTM=0ãªã‚‰ã€ç›´è¿‘æœ€å¤§2å›ã®åˆè¨ˆã€ã‚’ä»£æ›¿ã¨ã—ã¦è¿”ã™ï¼ˆæ—¥æœ¬æ ªã®å¹´2å›/å¹´1å›å¯¾ç­–ï¼‰
    """
    out = {
        "ttm_div": None, "yield_pct": None,
        "recent": pd.DataFrame(),
        "alt_div": None, "alt_yield": None,
        "method": "none"
    }
    try:
        ticker = yf.Ticker(code)
        s = ticker.dividends

        # ä»£æ›¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆactions=Trueã§é…å½“åˆ—ç¢ºä¿ï¼‰
        if s is None or len(s)==0 or float(getattr(s,"sum",lambda:0)())==0:
            df_dl = yf.download(code, period="5y", interval="1d",
                                actions=True, auto_adjust=False, progress=False)
            if isinstance(df_dl, pd.DataFrame) and "Dividends" in df_dl.columns:
                s = df_dl["Dividends"]
            else:
                s = pd.Series(dtype="float64")

        if s is None or len(s)==0:
            return out

        s = s[s > 0]
        if len(s)==0:
            return out

        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ç„¡åŠ¹åŒ–ï¼ˆã‚ã‚Œã°ï¼‰
        if getattr(s.index, "tz", None) is not None:
            s.index = s.index.tz_convert(None)

        now = pd.Timestamp.utcnow().tz_localize(None)
        ttm = s[s.index >= now - pd.Timedelta(days=ttm_days)]
        ttm_sum = float(ttm.sum()) if len(ttm) else 0.0

        if ttm_sum > 0:
            out["ttm_div"] = ttm_sum
            out["method"] = "ttm"
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç›´è¿‘æœ€å¤§2å›ï¼ˆæ—¥æœ¬æ ªã®åŠæœŸé…å½“/å¹´1å›ã«ã‚‚å¯¾å¿œï¼‰
            last_two = s.sort_index(ascending=False).head(2)
            alt_sum = float(last_two.sum()) if len(last_two) else 0.0
            if alt_sum > 0:
                out["alt_div"] = alt_sum
                out["method"] = "fallback_last2"

        # åˆ©å›ã‚Šè¨ˆç®—
        if last_close:
            if out["ttm_div"] is not None:
                out["yield_pct"] = out["ttm_div"] / float(last_close) * 100.0
            if out["alt_div"] is not None:
                out["alt_yield"] = out["alt_div"] / float(last_close) * 100.0

        # ç›´è¿‘å±¥æ­´ï¼ˆè¦‹ã‚„ã™ã•å„ªå…ˆã§8ä»¶ï¼‰
        recent = s.sort_index(ascending=False).head(8).reset_index()
        recent.columns = ["date","dividend"]
        out["recent"] = recent
    except Exception:
        pass
    return out


# ========= UI =========
st.set_page_config(page_title="éŠ˜æŸ„ãƒ€ãƒƒã‚·ãƒ¥ - ãƒ—ãƒ­ãƒˆ", layout="wide")
st.title("ğŸ“ˆ éŠ˜æŸ„ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯è¦ç´„")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: ã‚¨ã‚¤ãƒªã‚¢ã‚¹ç®¡ç†
st.sidebar.markdown("### ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ï¼ˆExcel/CSVï¼‰")
alias_df = load_alias_from_disk()
if ALIAS_PATH.exists():
    st.sidebar.caption(f"ä¿å­˜å…ˆ: `{ALIAS_PATH}`")
else:
    st.sidebar.caption("ä¿å­˜å…ˆ: ãªã—ï¼ˆåˆå›ã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¿å­˜ï¼‰")

uploaded = st.sidebar.file_uploader("ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆxlsx/csv/txtï¼‰", type=["xlsx","xls","csv","txt"])
c1, c2 = st.sidebar.columns(2)
with c1:
    if uploaded is not None and st.sidebar.button("ä¿å­˜/å·®ã—æ›¿ãˆ", use_container_width=True):
        try:
            path = save_uploaded_alias(uploaded)
            st.sidebar.success(f"ä¿å­˜ã—ã¾ã—ãŸ: {path}")
        except Exception as e:
            st.sidebar.error(f"ä¿å­˜å¤±æ•—: {e}")
with c2:
    if st.sidebar.button("ç¾åœ¨ã®è¡¨ã‚’DL", use_container_width=True):
        st.session_state["dl_alias"] = True
if st.session_state.get("dl_alias"):
    st.info("ç¾åœ¨ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ï¼ˆxlsxï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
    download_current_alias_button(alias_df)
    st.session_state["dl_alias"] = False

# ===== å…¥åŠ›æ¬„ï¼šã‚¯ãƒªã‚¢/æŒ¿å…¥ãƒ•ãƒ©ã‚°ã®é©ç”¨ã‚’â€œæç”»å‰â€ã«ã‚„ã‚‹ =====
if "code_input" not in st.session_state:
    st.session_state["code_input"] = "5108.T"

# ã‚¯ãƒªã‚¢è¦æ±‚ãƒ•ãƒ©ã‚°
if st.session_state.get("clear_code_flag"):
    st.session_state["code_input"] = ""
    st.session_state["clear_code_flag"] = False

# æŒ¿å…¥è¦æ±‚ãƒ•ãƒ©ã‚°
if "pending_code" in st.session_state:
    st.session_state["code_input"] = st.session_state["pending_code"]
    del st.session_state["pending_code"]

# ===== å…¥åŠ›æ¬„ï¼†ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ï¼ˆã‚ºãƒ¬è§£æ¶ˆï¼šå…±é€šãƒ©ãƒ™ãƒ«ï¼‹ç¸¦ä¸­å¤®æƒãˆï¼‰ =====
st.markdown("**è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰ or ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ï¼š5020.T / 5108.T / 7611.T / AAPLï¼‰**")
col_code, col_clear = st.columns([8, 2], vertical_alignment="center")
with col_code:
    st.text_input(
        label="ã‚³ãƒ¼ãƒ‰",
        key="code_input",
        label_visibility="collapsed",   # ãƒ©ãƒ™ãƒ«ã¯ä¸Šã®markdownã«é›†ç´„
        placeholder="ä¾‹ï¼‰5108.T",
    )
with col_clear:
    if st.button("ã‚¯ãƒªã‚¢", use_container_width=True):
        st.session_state["clear_code_flag"] = True
        st.rerun()

# ===== ã‚¨ã‚¤ãƒªã‚¢ã‚¹æ¤œç´¢ï¼†ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ï¼‹ã‚³ãƒ”ãƒ¼/æŒ¿å…¥ï¼‰ =====
st.subheader("ğŸ” ã‚¨ã‚¤ãƒªã‚¢ã‚¹æ¤œç´¢ & ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
search_q = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚³ãƒ¼ãƒ‰/éŠ˜æŸ„åã®éƒ¨åˆ†ä¸€è‡´ï¼‰", value="", key="alias_search_q")

filtered_df = alias_df
if search_q:
    qn = _norm(search_q).lower()
    filtered_df = alias_df[alias_df.apply(
        lambda r: qn in str(r["ticker"]).lower() or qn in str(r["alias"]).lower(), axis=1
    )]

with st.expander("ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ï¼‰", expanded=False):
    st.dataframe(filtered_df, use_container_width=True, hide_index=True)
    if not filtered_df.empty:
        st.markdown("**ã‚¯ã‚¤ãƒƒã‚¯æ“ä½œï¼ˆå…ˆé ­50ä»¶ï¼‰**")
        for i, row in filtered_df.head(50).iterrows():
            col1, col2, col3, col4 = st.columns([2, 5, 2, 2], vertical_alignment="center")
            with col1:
                st.write(f"{row['ticker']}")
            with col2:
                st.write(f"{row['alias']}")
            with col3:
                copy_button(row["ticker"], "ã‚³ãƒ”ãƒ¼", key=f"copy-{i}")
            with col4:
                if st.button(f"{row['ticker']} ã‚’æŒ¿å…¥", key=f"ins-{i}", use_container_width=True):
                    st.session_state["pending_code"] = row["ticker"]
                    st.rerun()
    else:
        st.info("ä¸€è‡´ã™ã‚‹éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# è¡¨ç¤ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
st.sidebar.markdown("---")
period = st.sidebar.selectbox("æœŸé–“", ["1mo","3mo","6mo","1y"], index=1)
interval = st.sidebar.selectbox("è¶³", ["1d","1wk","1mo"], index=0)
use_zero_base = st.sidebar.checkbox("Yè»¸ã‚’0ã‹ã‚‰ã«ã™ã‚‹", value=False)

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
if st.button("ç”Ÿæˆ", type="primary"):
    code = st.session_state.get("code_input","").strip()
    if not code:
        st.warning("ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        ticker = yf.Ticker(code)
        df = ticker.history(period=period, interval=interval)

        info = {}
        try: info = ticker.get_info()
        except Exception: pass
        name = display_name_for(code, alias_df, info)
        title_text = f"{name}ï¼ˆ{code}ï¼‰"

        if not df.empty:
            st.subheader(f"{title_text} â€“ ãƒãƒ£ãƒ¼ãƒˆ")
            copy_button(code, "ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼", key="title-copy")

            chart_df = df.reset_index().rename(columns={"Date":"date"})
            ymin, ymax = float(df["Close"].min()), float(df["Close"].max())
            y_scale = alt.Scale(domain=[0, ymax*1.05]) if use_zero_base else alt.Scale(domain=[ymin*0.98, ymax*1.02])
            line = (
                alt.Chart(chart_df)
                .mark_line()
                .encode(
                    x=alt.X("date:T", axis=alt.Axis(title=None)),
                    y=alt.Y("Close:Q", axis=alt.Axis(title=None), scale=y_scale),
                    tooltip=[
                        alt.Tooltip("date:T",  title="æ—¥ä»˜"),
                        alt.Tooltip("Close:Q", title="çµ‚å€¤", format=".2f"),
                        alt.Tooltip("Open:Q",  title="å§‹å€¤", format=".2f"),
                        alt.Tooltip("High:Q",  title="é«˜å€¤", format=".2f"),
                        alt.Tooltip("Low:Q",   title="å®‰å€¤", format=".2f"),
                    ],
                )
                .properties(height=260)
                .interactive()
            )
            st.altair_chart(line, use_container_width=True)
            change = (df["Close"][-1]-df["Close"][0]) / df["Close"][0] * 100
            st.caption(f"æœŸé–“: {len(df)}æœ¬, å§‹å€¤={df['Open'][0]:.2f}, çµ‚å€¤={df['Close'][-1]:.2f}, å¤‰åŒ–ç‡={change:+.2f}%")
        else:
            st.info("ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        # é…å½“
        st.subheader("ğŸ’´ é…å½“ï¼ˆç›´è¿‘1å¹´TTMï¼å‚è€ƒï¼‰")
        last_close = float(df["Close"][-1]) if not df.empty else 0.0
        div_info = get_dividend_info(code, last_close)

        if div_info["ttm_div"] is not None:
            yld = f"{div_info['yield_pct']:.2f}%" if div_info['yield_pct'] is not None else "â€”"
            st.write(f"TTMé…å½“åˆè¨ˆ: **{div_info['ttm_div']:.2f}** / å‚è€ƒåˆ©å›ã‚Š: **{yld}**ï¼ˆæ–¹æ³•: TTM {400}æ—¥ï¼‰")
        elif div_info["alt_div"] is not None:
            alt_yld = f"{div_info['alt_yield']:.2f}%" if div_info['alt_yield'] is not None else "â€”"
            st.write(f"TTMé…å½“åˆè¨ˆ: â€” / ä»£æ›¿ï¼ˆç›´è¿‘æœ€å¤§2å›ã®åˆè¨ˆï¼‰: **{div_info['alt_div']:.2f}** / å‚è€ƒåˆ©å›ã‚Š: **{alt_yld}**")
        else:
            st.write("é…å½“ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        if not div_info["recent"].empty:
            st.dataframe(
                div_info["recent"].rename(columns={"date":"æ—¥ä»˜","dividend":"é…å½“(1æ ª)"}),
                use_container_width=True
            )

        # æ ªä¸»å„ªå¾…ãƒªãƒ³ã‚¯
        st.markdown(
            "ğŸ”— æ ªä¸»å„ªå¾…æƒ…å ±ã¯ä»¥ä¸‹ã®å¤–éƒ¨ã‚µã‚¤ãƒˆã§ç¢ºèªã§ãã¾ã™ï¼š\n"
            "[æ ªä¸»å„ªå¾…ã‚’æ¢ã™ï¼ˆkabuyutai.comï¼‰](https://www.kabuyutai.com/)"
        )

        # ãƒ‹ãƒ¥ãƒ¼ã‚¹
        st.subheader("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆGoogle News RSSï¼‰")
        news = fetch_news_for(code, alias_df=alias_df, days=30, max_items=8, strict_title=True, min_score=2)
        if news:
            for n in news:
                st.markdown(f"- [{n['title']}]({n['link']}) ã€”score={n['score']}ã€•")
        else:
            st.write("ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

st.caption("Powered by Streamlit / yfinance / Google News RSS")
