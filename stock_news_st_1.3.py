# stock_news_st

# -*- coding: utf-8 -*-
"""
éŠ˜æŸ„ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯è¦ç´„ï¼ˆGoogle Sheets é€£æºãƒ»ã‚¨ã‚¤ãƒªã‚¢ã‚¹æ­£æœ¬ï¼‰
- ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ã¯ Google ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ­£æœ¬ï¼ˆå„ªå…ˆï¼‰
- GS ãŒç©º/æ¥ç¶šä¸å¯ãªã‚‰ãƒ­ãƒ¼ã‚«ãƒ« aliases.xlsx ã«è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¿å­˜æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«â†’GS åŒæœŸã‚’è©¦è¡Œï¼ˆå¤±æ•—æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ï¼‰
- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã€ŒGSâ†’ãƒ­ãƒ¼ã‚«ãƒ«ã€ã€Œãƒ­ãƒ¼ã‚«ãƒ«â†’GSã€ã€ŒGSå†èª­è¾¼ã€ãƒœã‚¿ãƒ³
- æ—¥æœ¬èªæ¤œå‡ºã¯ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¯„å›²ã§å®‰å…¨ã«ï¼ˆæ–‡å­—åŒ–ã‘è€æ€§ï¼‰
- ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆåãŒåˆã‚ãªã„æ™‚ã¯**å…ˆé ­ã‚¿ãƒ–ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**
- â˜… èªè¨¼æ”¹å–„ï¼šJSONãƒ•ã‚¡ã‚¤ãƒ«ç›´èª­ã¿â†’secrets ã®é †ã«è©¦è¡Œï¼ˆãƒ†ã‚¹ãƒˆã¨åŒã˜æ‰‹é †ã‚’æœ€å„ªå…ˆï¼‰
- â˜… è¨­å®šæ”¹å–„ï¼šsheet_id / worksheet ã¯ secrets ãŒç„¡ã‘ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®šæ•°ã‚’ä½¿ç”¨
"""

from __future__ import annotations

import io
import os
import re
import unicodedata
from pathlib import Path
from html import escape
import urllib.parse
from typing import Tuple

import pandas as pd
import streamlit as st
import streamlit.components.v1 as components
import yfinance as yf
import feedparser  # type: ignore
import altair as alt

# === Google Sheets ===
import gspread  # type: ignore
from gspread.exceptions import WorksheetNotFound  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨
from google.oauth2.service_account import Credentials  # type: ignore

# ========= åŸºæœ¬è¨­å®š =========
st.set_page_config(page_title="éŠ˜æŸ„ãƒ€ãƒƒã‚·ãƒ¥ - GSåŒæœŸ", layout="wide")

DATA_DIR = Path("data")
ALIAS_PATH = DATA_DIR / "aliases.xlsx"  # ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¿å­˜å…ˆ
DEFAULT_COLUMNS = ["ticker", "alias"]
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]

# ========= â˜… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šï¼ˆã‚ãªãŸã®ç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´å¯ï¼‰ =========
# ãƒ†ã‚¹ãƒˆã§é€šã£ãŸ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ï¼ˆå­˜åœ¨ã™ã‚Œã°ã“ã‚Œã‚’æœ€å„ªå…ˆï¼‰
SERVICE_ACCOUNT_JSON_PATH = r"C:\STOCK_NEWS_ST_1.0\stock-news-st-f1bc5054f582.json"
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã‚‚æŒ‡å®šå¯èƒ½ï¼ˆå„ªå…ˆåº¦ï¼šã“ã®ç’°å¢ƒå¤‰æ•° > ä¸Šã®å®šæ•°ï¼‰
ENV_JSON_PATH_KEY = "SERVICE_ACCOUNT_JSON_PATH"

# secrets ãŒç„¡ã„/æœªè¨­å®šã§ã‚‚å‹•ãã‚ˆã†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ã‚·ãƒ¼ãƒˆæƒ…å ±
SHEET_ID_FALLBACK = "1wfjQnNGJhmhZI7bZ3lK_dIjrpi8Ilwn8Es_9X0vQFqo"
WORKSHEET_NAME_FALLBACK = "aliases"

def _cfg_sheet_id() -> str:
    try:
        return st.secrets["gsheet"]["sheet_id"]
    except Exception:
        return SHEET_ID_FALLBACK

def _cfg_worksheet_name() -> str:
    try:
        return st.secrets["gsheet"].get("worksheet", "aliases")
    except Exception:
        return WORKSHEET_NAME_FALLBACK

# ========= ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========
def _norm(s: str) -> str:
    return unicodedata.normalize("NFKC", str(s)).strip()

def _has_japanese(s: str) -> bool:
    """æ–‡å­—åŒ–ã‘ã«å¼·ã„æ—¥æœ¬èªæ¤œå‡ºï¼ˆã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ¤å®šï¼‰"""
    for ch in str(s):
        cp = ord(ch)
        if (
            0x3040 <= cp <= 0x309F   # ã²ã‚‰ãŒãª
            or 0x30A0 <= cp <= 0x30FF  # ã‚«ã‚¿ã‚«ãƒŠ
            or 0x4E00 <= cp <= 0x9FFF  # CJKçµ±åˆæ¼¢å­—
            or 0xFF66 <= cp <= 0xFF9D  # åŠè§’ï½¶ï¾…
            or cp in (0x30FB, 0x30FC, 0xFF70)  # ãƒ», ãƒ¼, ï½°
        ):
            return True
    return False

def _ensure_dir(p: Path):
    p.parent.mkdir(parents=True, exist_ok=True)

def _validate_alias_df(df: pd.DataFrame) -> pd.DataFrame:
    """åˆ—åãƒ»å‹ã‚’æ¨™æº–åŒ–ã—ã€é‡è¤‡/æ¬ æã‚’æ•´ç†ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ã®æºã‚Œã«ã‚‚ã‚ã‚‹ç¨‹åº¦è€æ€§ï¼‰"""
    if df is None or df.empty:
        return pd.DataFrame(columns=DEFAULT_COLUMNS)

    df = df.copy()

    # åˆ—åã‚«ãƒãƒŠã‚¤ã‚ºï¼ˆç©ºç™½ãƒ»è¨˜å·é™¤å»ã€å‰æ–¹ä¸€è‡´è¨±å®¹ï¼‰
    def _canon(c: str) -> str:
        c = unicodedata.normalize("NFKC", str(c)).strip().lower()
        c = re.sub(r"[\s\-\_\.\(\)ã€€]+", "", c)
        return c

    col_map: dict[str, str] = {}
    for c in list(df.columns):
        key = _canon(c)
        if key.startswith("ticker") or key in {"code", "ãƒ†ã‚£ãƒƒã‚«ãƒ¼", "ã‚³ãƒ¼ãƒ‰"}:
            col_map[c] = "ticker"
        elif key.startswith("alias") or key in {"name", "ã‚¨ã‚¤ãƒªã‚¢ã‚¹", "éŠ˜æŸ„å"}:
            col_map[c] = "alias"

    df.columns = [col_map.get(c, c) for c in df.columns]

    for col in DEFAULT_COLUMNS:
        if col not in df.columns:
            df[col] = ""

    df = df[DEFAULT_COLUMNS].copy()
    df["ticker"] = df["ticker"].map(_norm)
    df["alias"]  = df["alias"].map(_norm)

    # ç©ºtickerè¡Œã¯å‰Šé™¤ã€é‡è¤‡ã¯æœ€å¾Œæ¡ç”¨
    df = df[df["ticker"] != ""]
    df = df.drop_duplicates(subset=["ticker"], keep="last").reset_index(drop=True)
    return df

def _read_any_to_df(uploaded_file) -> pd.DataFrame:
    """xlsx/csv/txt(ã‚¿ãƒ–/ã‚«ãƒ³ãƒ)ã«å¯¾å¿œã—ã¦DataFrameåŒ–"""
    fname = uploaded_file.name.lower()
    try:
        if fname.endswith((".xlsx", ".xls")):
            return pd.read_excel(uploaded_file)
        elif fname.endswith((".csv", ".txt")):
            # ã‚«ãƒ³ãƒ â†’ ã‚¿ãƒ–ã®é †ã«è©¦ã™
            try:
                return pd.read_csv(uploaded_file)
            except Exception:
                uploaded_file.seek(0)
                return pd.read_csv(uploaded_file, sep="\t")
        else:
            raise ValueError("å¯¾å¿œæ‹¡å¼µå­ã¯ .xlsx/.xls/.csv/.txt ã§ã™ã€‚")
    except Exception as e:
        raise RuntimeError(f"èª­è¾¼å¤±æ•—: {e}")

# ========= ãƒ­ãƒ¼ã‚«ãƒ« I/O =========
@st.cache_data(ttl=600, show_spinner=False)
def load_alias_from_disk() -> pd.DataFrame:
    if ALIAS_PATH.exists():
        ext = ALIAS_PATH.suffix.lower()
        try:
            if ext in (".xlsx", ".xls"):
                df = pd.read_excel(ALIAS_PATH)
            elif ext in (".csv", ".txt"):
                df = pd.read_csv(ALIAS_PATH)
            else:
                return pd.DataFrame(columns=DEFAULT_COLUMNS)
            return _validate_alias_df(df)
        except Exception:
            pass
    return pd.DataFrame(columns=DEFAULT_COLUMNS)

def save_alias_to_disk(df: pd.DataFrame) -> Path:
    _ensure_dir(ALIAS_PATH)
    target = ALIAS_PATH.with_suffix(".xlsx")
    tmp = target.with_suffix(".xlsx.tmp")
    with pd.ExcelWriter(tmp, engine="xlsxwriter") as w:
        _validate_alias_df(df).to_excel(w, index=False)
    if target.exists():
        target.unlink()
    tmp.rename(target)
    load_alias_from_disk.clear()
    return target

def save_uploaded_alias(uploaded_file) -> Path:
    df = _read_any_to_df(uploaded_file)
    path = save_alias_to_disk(df)
    return path

def download_current_alias_button(df: pd.DataFrame):
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as w:
        (_validate_alias_df(df) if not df.empty else pd.DataFrame(columns=DEFAULT_COLUMNS)).to_excel(w, index=False)
    st.download_button(
        "ç¾åœ¨ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆxlsxï¼‰",
        data=buf.getvalue(),
        file_name="aliases.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True,
    )

# ========= Google Sheets I/Oï¼ˆâ˜… æ”¹å–„ç‚¹ã‚ã‚Šï¼‰ =========
def _gs_client():
    """
    èªè¨¼å„ªå…ˆåº¦:
      1) ç’°å¢ƒå¤‰æ•° SERVICE_ACCOUNT_JSON_PATH ã®ãƒ‘ã‚¹
      2) å®šæ•° SERVICE_ACCOUNT_JSON_PATH ã®ãƒ‘ã‚¹
      3) st.secrets['gcp_service_account'] ã®JSONå†…å®¹
    """
    # 1) ç’°å¢ƒå¤‰æ•°
    json_path_env = os.environ.get(ENV_JSON_PATH_KEY, "").strip()
    if json_path_env and Path(json_path_env).exists():
        try:
            creds = Credentials.from_service_account_file(json_path_env, scopes=SCOPES)
            return gspread.authorize(creds)
        except Exception:
            pass
    # 2) å®šæ•°ã®ãƒ‘ã‚¹
    if SERVICE_ACCOUNT_JSON_PATH and Path(SERVICE_ACCOUNT_JSON_PATH).exists():
        try:
            creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_JSON_PATH, scopes=SCOPES)
            return gspread.authorize(creds)
        except Exception:
            pass
    # 3) secrets.toml ã® JSON æœ¬æ–‡
    try:
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=SCOPES)
        return gspread.authorize(creds)
    except Exception:
        return None

def _gs_ws():
    """ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’å–å¾—ã€‚æŒ‡å®šåãŒç„¡ã‘ã‚Œã°**å…ˆé ­ã‚¿ãƒ–**ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        gc = _gs_client()
        if not gc:
            return None
        sh = gc.open_by_key(_cfg_sheet_id())
        ws_name = _cfg_worksheet_name()
        try:
            return sh.worksheet(ws_name)
        except WorksheetNotFound:
            return sh.get_worksheet(0)  # å…ˆé ­ã‚¿ãƒ–
    except Exception:
        return None

@st.cache_data(ttl=600, show_spinner=False)
def load_alias_from_gs() -> pd.DataFrame:
    """
    get_all_values ãƒ™ãƒ¼ã‚¹ã§å–å¾—ã—ã€æœ€åˆã®éç©ºè¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦è§£é‡ˆã€‚
    get_all_records ã®ç™–ï¼ˆç©ºè¡Œãƒ»ä¸å¯è¦–æ–‡å­—ãƒ»çµåˆã‚»ãƒ«ç­‰ï¼‰ã«å¼·ãã™ã‚‹ã€‚
    """
    ws = _gs_ws()
    if not ws:
        return pd.DataFrame(columns=DEFAULT_COLUMNS)
    try:
        vals = ws.get_all_values()  # [[cell,...], ...]
        # æœ€åˆã®éç©ºè¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã™ã‚‹
        header_idx = next((i for i, row in enumerate(vals) if any(str(c).strip() for c in row)), None)
        if header_idx is None:
            return pd.DataFrame(columns=DEFAULT_COLUMNS)

        header = [str(c).strip() for c in vals[header_idx]]
        data = vals[header_idx + 1:]

        # åˆ—æ•°ã‚’åˆã‚ã›ã‚‹ï¼ˆè¶³ã‚Šãªã„åˆ—ã¯ç©ºã§åŸ‹ã‚ã‚‹ï¼‰
        width = max([len(header)] + [len(r) for r in data]) if data else len(header)
        header = (header + [""] * (width - len(header)))[:width]
        rows = [(r + [""] * (width - len(r)))[:width] for r in data]

        df = pd.DataFrame(rows, columns=header)
        return _validate_alias_df(df)
    except Exception:
        return pd.DataFrame(columns=DEFAULT_COLUMNS)

def save_alias_to_gs(df: pd.DataFrame) -> str:
    ws = _gs_ws()
    if not ws:
        raise RuntimeError("Google Sheets ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚secrets ã¨å…±æœ‰è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    df = _validate_alias_df(df)
    # å…¨ç½®æ›ã§æ›´æ–°
    ws.clear()
    header = list(df.columns)
    values = [header] + df.astype(str).values.tolist()
    ws.update(values)
    # ä»»æ„ã§æœ€çµ‚æ›´æ–°ãƒ¡ãƒ¢
    try:
        ws.update_acell("D1", "last_updated")
        ws.update_acell("E1", pd.Timestamp.now(tz="Asia/Tokyo").strftime("%Y-%m-%d %H:%M:%S"))
    except Exception:
        pass
    load_alias_from_gs.clear()
    return "Google Sheets ã¸åŒæœŸã—ã¾ã—ãŸã€‚"

# ========= ã‚¯ãƒªãƒƒãƒ—ãƒœã‚¿ãƒ³ =========
def copy_button(text: str, label: str, key: str):
    """iframeå†…ã§ã‚‚å‹•ãã‚³ãƒ”ãƒ¼ï¼ˆãƒ¢ãƒ€ãƒ³APIâ†’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    safe_text  = escape(text).replace("'", "&#39;")
    safe_label = escape(label)
    html = f"""
    <button id="{key}" style="
        padding:6px 10px;border-radius:8px;border:1px solid #555;
        background:#1f6feb;color:#fff;cursor:pointer">
        {safe_label}
    </button>
    <script>
      (function(){{
        const btn = document.getElementById("{key}");
        if (!btn) return;
        btn.addEventListener("click", async () => {{
          const val = "{safe_text}";
          async function modernCopy() {{
            try {{
              await navigator.clipboard.writeText(val);
              return true;
            }} catch(e) {{ return false; }}
          }}
          function legacyCopy(){{
            try {{
              const ta = document.createElement('textarea');
              ta.value = val;
              ta.style.position='fixed';
              ta.style.left='-9999px';
              document.body.appendChild(ta);
              ta.select();
              document.execCommand('copy');
              document.body.removeChild(ta);
              return true;
            }} catch(e) {{ return false; }}
          }}
          const ok = (navigator.clipboard && await modernCopy()) || legacyCopy();
          const prev = btn.innerText;
          btn.innerText = ok ? "ã‚³ãƒ”ãƒ¼æ¸ˆ" : "ã‚³ãƒ”ãƒ¼å¤±æ•—";
          setTimeout(()=>{{ btn.innerText = prev; }}, 1000);
        }});
      }})();
    </script>
    """
    components.html(html, height=42)

# ========= è¡¨ç¤ºå =========
def display_name_for(code: str, alias_df: pd.DataFrame | None, info: dict | None) -> str:
    code = _norm(code)
    if alias_df is not None and not alias_df.empty:
        cand = alias_df.loc[alias_df["ticker"] == code, "alias"].tolist()
        jp = [a for a in cand if _has_japanese(a)]
        if jp: return max(jp, key=len)
    if info:
        for k in ("longName","shortName"):
            v = info.get(k)
            if v: return str(v)
    return code

# ========= ãƒ‹ãƒ¥ãƒ¼ã‚¹ =========
def _aliases_for(code: str, alias_df: pd.DataFrame | None = None):
    code = _norm(code)
    aliases = {code, code.replace(".T","")}
    info = {}
    try:
        t = yf.Ticker(code)
        try: info = t.get_info()
        except Exception: pass
        for k in ("longName","shortName"):
            v = info.get(k)
            if v: aliases.add(_norm(v))
    except Exception:
        pass
    if alias_df is not None and not alias_df.empty:
        extra = alias_df.loc[alias_df["ticker"] == code, "alias"].tolist()
        for a in extra:
            if a: aliases.add(_norm(a))
    manual = {"7611.T": ["ãƒã‚¤ãƒ‡ã‚¤æ—¥é«˜","æ—¥é«˜å±‹"], "5020.T": ["ï¼¥ï¼®ï¼¥ï¼¯ï¼³","ENEOS"]}
    for v in manual.get(code, []):
        aliases.add(_norm(v))
    return [a for a in aliases if a]

def _score_title(title: str, terms: list[str], code: str) -> int:
    t = _norm(title).lower(); score = 0
    for a in terms:
        a_norm = _norm(a).lower()
        if a_norm and a_norm in t: score += 2
    core = code.replace(".T","")
    if re.search(rf"(?:\(|ï¼ˆ|ã€){core}(?:\)|ï¼‰|ã€‘)", t): score += 2
    if core in t: score += 1
    return score

_EXCLUDE_TERMS = ["ã‚²ãƒ¼ãƒ ","ã‚¹ãƒ—ãƒ©","splatoon","ã‚®ã‚¢","ãƒ•ã‚§ã‚¹","OCEANS","ã‚ªãƒ¼ã‚·ãƒ£ãƒ³ã‚º"]

def fetch_news_for(code: str, alias_df: pd.DataFrame | None, days: int = 30, max_items: int = 10,
                   strict_title=True, min_score=2):
    terms = _aliases_for(code, alias_df=alias_df)
    quoted_terms = [f'"{t}"' for t in terms]
    must_have = "(æ ªä¾¡ OR æ±ºç®— OR IR OR æ¥­ç¸¾ OR å‡ºåº— OR æ—¢å­˜åº— OR æœˆæ¬¡ OR å£²ä¸Š)"
    exclude   = "-ã‚²ãƒ¼ãƒ  -ã‚¹ãƒ—ãƒ© -Splatoon -ã‚®ã‚¢ -eã‚¹ãƒãƒ¼ãƒ„ -ãƒ•ã‚§ã‚¹ -OCEANS"
    q = f'({" OR ".join(quoted_terms)}) {must_have} {exclude} when:{days}d'

    url = "https://news.google.com/rss/search?" + urllib.parse.urlencode({
        "q": q, "hl":"ja", "gl":"JP", "ceid":"JP:ja",
    })
    feed = feedparser.parse(url)

    pool = []
    for e in feed.entries[: max_items*3]:
        title = getattr(e,"title","")
        if not title: continue
        low = title.lower()
        if any(x.lower() in low for x in _EXCLUDE_TERMS): continue
        score = _score_title(title, terms, code)
        if (not strict_title) or (score >= min_score):
            pool.append({
                "title": title,
                "link": getattr(e,"link",""),
                "published": getattr(e,"published",""),
                "score": score,
            })
    pool.sort(key=lambda x: (x["score"], x.get("published","")), reverse=True)
    return pool[:max_items]

# ========= é…å½“ï¼ˆTTM + ä»£æ›¿ï¼‰ =========
def get_dividend_info(code: str, last_close: float, ttm_days: int = 400) -> dict:
    """
    - yfinanceã®dividendsï¼ˆSeries, index=Datetimeï¼‰ã‚’å–å¾—
    - TTMã¯éå»ttm_daysã§åˆè¨ˆã€0ãªã‚‰ç›´è¿‘æœ€å¤§2å›ã®åˆè¨ˆã‚’ä»£æ›¿
    """
    out = {
        "ttm_div": None, "yield_pct": None,
        "recent": pd.DataFrame(),
        "alt_div": None, "alt_yield": None,
        "method": "none"
    }
    try:
        ticker = yf.Ticker(code)
        s = ticker.dividends

        # ä»£æ›¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆactions=Trueã§é…å½“åˆ—ç¢ºä¿ï¼‰
        if s is None or len(s)==0 or float(getattr(s,"sum",lambda:0)())==0:
            df_dl = yf.download(code, period="5y", interval="1d",
                                actions=True, auto_adjust=False, progress=False)
            if isinstance(df_dl, pd.DataFrame) and "Dividends" in df_dl.columns:
                s = df_dl["Dividends"]
            else:
                s = pd.Series(dtype="float64")

        if s is None or len(s)==0:
            return out

        s = s[s > 0]
        if len(s)==0:
            return out

        if getattr(s.index, "tz", None) is not None:
            s.index = s.index.tz_convert(None)

        now = pd.Timestamp.utcnow().tz_localize(None)
        ttm = s[s.index >= now - pd.Timedelta(days=ttm_days)]
        ttm_sum = float(ttm.sum()) if len(ttm) else 0.0

        if ttm_sum > 0:
            out["ttm_div"] = ttm_sum
            out["method"] = "ttm"
        else:
            last_two = s.sort_index(ascending=False).head(2)
            alt_sum = float(last_two.sum()) if len(last_two) else 0.0
            if alt_sum > 0:
                out["alt_div"] = alt_sum
                out["method"] = "fallback_last2"

        if last_close:
            if out["ttm_div"] is not None:
                out["yield_pct"] = out["ttm_div"] / float(last_close) * 100.0
            if out["alt_div"] is not None:
                out["alt_yield"] = out["alt_div"] / float(last_close) * 100.0

        recent = s.sort_index(ascending=False).head(8).reset_index()
        recent.columns = ["date","dividend"]
        out["recent"] = recent
    except Exception:
        pass
    return out

# ========= UIï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šGSåŒæœŸã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ï¼‰ =========
st.title("ğŸ“ˆ éŠ˜æŸ„ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯è¦ç´„ï¼ˆGSåŒæœŸç‰ˆï¼‰")
st.caption("ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ã¯ Google ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’å„ªå…ˆã€‚å¤±æ•—æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã¸è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚")

@st.cache_data(ttl=600, show_spinner=False)
def _load_alias_preferring_gs() -> tuple[pd.DataFrame, bool]:
    df_gs = load_alias_from_gs()
    if not df_gs.empty:
        return df_gs, True
    return load_alias_from_disk(), False

def sidebar_controls() -> Tuple[pd.DataFrame, bool]:
    alias_df, using_gs = _load_alias_preferring_gs()

    st.sidebar.markdown("### ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ï¼ˆExcel/CSV â‡„ GSï¼‰")
    if using_gs:
        st.sidebar.success("GSï¼ˆ10åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ã‹ã‚‰èª­ã¿è¾¼ã¿ä¸­")
    else:
        if ALIAS_PATH.exists():
            st.sidebar.warning("GSãŒç©º/æ¥ç¶šä¸å¯ã®ãŸã‚ãƒ­ãƒ¼ã‚«ãƒ«ã‚’ä½¿ç”¨ä¸­")
        else:
            st.sidebar.warning("GSæœªæ¥ç¶š & ãƒ­ãƒ¼ã‚«ãƒ«ã‚‚æœªè¨­å®šã€‚ã¾ãšã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

    if ALIAS_PATH.exists():
        st.sidebar.caption(f"ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜å…ˆ: `{ALIAS_PATH}`")

    uploaded = st.sidebar.file_uploader("ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆxlsx/csv/txtï¼‰", type=["xlsx","xls","csv","txt"])
    c1, c2 = st.sidebar.columns(2)
    with c1:
        if uploaded is not None and st.sidebar.button("ä¿å­˜/å·®ã—æ›¿ãˆ", use_container_width=True):
            try:
                path = save_uploaded_alias(uploaded)  # ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜
                st.sidebar.success(f"ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜: {path}")
                # GS åŒæœŸ
                try:
                    df_local = load_alias_from_disk()
                    msg = save_alias_to_gs(df_local)
                    st.sidebar.success(msg)
                except Exception as e:
                    st.sidebar.info(f"GSåŒæœŸã¯ã‚¹ã‚­ãƒƒãƒ—: {e}")
                _load_alias_preferring_gs.clear()
                st.rerun()
            except Exception as e:
                st.sidebar.error(f"ä¿å­˜å¤±æ•—: {e}")
    with c2:
        if st.sidebar.button("ç¾åœ¨ã®è¡¨ã‚’DL", use_container_width=True):
            st.session_state["dl_alias"] = True

    st.sidebar.markdown("---")
    s1, s2 = st.sidebar.columns(2)
    with s1:
        if st.button("GSâ†’ãƒ­ãƒ¼ã‚«ãƒ«", use_container_width=True):
            try:
                df_gs_now = load_alias_from_gs()
                if df_gs_now.empty:
                    st.warning("GSãŒç©º/å–å¾—å¤±æ•—ã§ã™ã€‚")
                else:
                    _ensure_dir(ALIAS_PATH)
                    df_gs_now.to_excel(ALIAS_PATH.with_suffix(".xlsx"), index=False)
                    load_alias_from_disk.clear()
                    _load_alias_preferring_gs.clear()
                    st.success("Google Sheets ã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ã«åŒæœŸã—ã¾ã—ãŸã€‚")
            except Exception as e:
                st.error(f"GSâ†’ãƒ­ãƒ¼ã‚«ãƒ«å¤±æ•—: {e}")
    with s2:
        if st.button("ãƒ­ãƒ¼ã‚«ãƒ«â†’GS", use_container_width=True):
            try:
                df_local = load_alias_from_disk()
                if df_local.empty:
                    st.warning("ãƒ­ãƒ¼ã‚«ãƒ«ãŒç©ºã§ã™ã€‚")
                else:
                    msg = save_alias_to_gs(df_local)
                    _load_alias_preferring_gs.clear()
                    st.success(msg)
            except Exception as e:
                st.error(f"ãƒ­ãƒ¼ã‚«ãƒ«â†’GSå¤±æ•—: {e}")

    if st.sidebar.button("GSã‚’å†èª­è¾¼", use_container_width=True):
        load_alias_from_gs.clear()
        _load_alias_preferring_gs.clear()
        st.rerun()

    # â˜… è¨ºæ–­ï¼†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆä»»æ„ï¼‰
    with st.sidebar.expander("ğŸ”§ GSè¨ºæ–­ / ã‚­ãƒ£ãƒƒã‚·ãƒ¥"):
        if st.button("GSã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            load_alias_from_gs.clear()
            _load_alias_preferring_gs.clear()
            st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸æ›´æ–°ã§å†å–å¾—ã€‚")
        try:
            client_ok = _gs_client() is not None
            st.write("client:", "OK" if client_ok else "NG")
            ws = _gs_ws()
            st.write("worksheet:", getattr(ws, "title", None))
            if ws:
                vals = ws.get_all_values()
                st.write("rows:", len(vals))
                st.write("head:", vals[:3])
        except Exception as e:
            st.error(str(e))

    return alias_df, using_gs

alias_df, using_gs = sidebar_controls()

# ========= å…¥åŠ›æ¬„ï¼†ã‚¯ãƒªã‚¢ =========
if "code_input" not in st.session_state:
    st.session_state["code_input"] = "5108.T"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¾‹

# ã‚¯ãƒªã‚¢è¦æ±‚ãƒ•ãƒ©ã‚°å‡¦ç†
if st.session_state.get("clear_code_flag"):
    st.session_state["code_input"] = ""
    st.session_state["clear_code_flag"] = False

st.markdown("**è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰ or ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ï¼š5020.T / 5108.T / 7611.T / AAPLï¼‰**")
col_code, col_clear = st.columns([8, 2])
with col_code:
    st.text_input(
        label="ã‚³ãƒ¼ãƒ‰",
        key="code_input",
        label_visibility="collapsed",
        placeholder="ä¾‹ï¼‰5108.T",
    )
with col_clear:
    if st.button("ã‚¯ãƒªã‚¢", use_container_width=True):
        st.session_state["clear_code_flag"] = True
        st.rerun()

# ========= ã‚¨ã‚¤ãƒªã‚¢ã‚¹æ¤œç´¢ï¼†ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ =========
st.subheader("ğŸ” ã‚¨ã‚¤ãƒªã‚¢ã‚¹æ¤œç´¢ & ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
search_q = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚³ãƒ¼ãƒ‰/éŠ˜æŸ„åã®éƒ¨åˆ†ä¸€è‡´ï¼‰", value="", key="alias_search_q")

filtered_df = alias_df
if not alias_df.empty and search_q:
    qn = _norm(search_q).lower()
    filtered_df = alias_df[alias_df.apply(
        lambda r: qn in str(r["ticker"]).lower() or qn in str(r["alias"]).lower(), axis=1
    )]

with st.expander("ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ï¼‰", expanded=False):
    st.dataframe(filtered_df, use_container_width=True, hide_index=True)
    if not filtered_df.empty:
        st.markdown("**ã‚¯ã‚¤ãƒƒã‚¯æ“ä½œï¼ˆå…ˆé ­50ä»¶ï¼‰**")
        for i, row in filtered_df.head(50).iterrows():
            col1, col2, col3, col4 = st.columns([2, 5, 2, 2])
            with col1:
                st.write(f"{row['ticker']}")
            with col2:
                st.write(f"{row['alias']}")
            with col3:
                copy_button(row["ticker"], "ã‚³ãƒ”ãƒ¼", key=f"copy-{i}")
            with col4:
                if st.button(f"{row['ticker']} ã‚’æŒ¿å…¥", key=f"ins-{i}", use_container_width=True):
                    st.session_state["code_input"] = row["ticker"]
                    st.rerun()
    else:
        st.info("ä¸€è‡´ã™ã‚‹éŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# ========= ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¡¨ç¤ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ =========
st.sidebar.markdown("---")
period = st.sidebar.selectbox("æœŸé–“", ["1mo","3mo","6mo","1y"], index=1)
interval = st.sidebar.selectbox("è¶³", ["1d","1wk","1mo"], index=0)
use_zero_base = st.sidebar.checkbox("Yè»¸ã‚’0ã‹ã‚‰ã«ã™ã‚‹", value=False)

# ========= ç”Ÿæˆãƒœã‚¿ãƒ³æŠ¼ä¸‹ã§å®Ÿè¡Œ =========
if st.button("ç”Ÿæˆ", type="primary"):
    code = st.session_state.get("code_input","").strip()
    if not code:
        st.warning("ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        ticker = yf.Ticker(code)
        df = ticker.history(period=period, interval=interval)

        info = {}
        try: info = ticker.get_info()
        except Exception: pass
        name = display_name_for(code, alias_df, info)
        title_text = f"{name}ï¼ˆ{code}ï¼‰"

        # ---- ãƒãƒ£ãƒ¼ãƒˆ ----
        if not df.empty:
            st.subheader(f"{title_text} â€“ ãƒãƒ£ãƒ¼ãƒˆ")
            copy_button(code, "ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼", key="title-copy")

            chart_df = df.reset_index().rename(columns={"Date":"date"})
            ymin, ymax = float(df["Close"].min()), float(df["Close"].max())
            if use_zero_base:
                y_scale = alt.Scale(domain=[0, ymax*1.05])
            else:
                y_scale = alt.Scale(domain=[ymin*0.98, ymax*1.02])

            line = (
                alt.Chart(chart_df)
                .mark_line()
                .encode(
                    x=alt.X("date:T", axis=alt.Axis(title=None)),
                    y=alt.Y("Close:Q", axis=alt.Axis(title=None), scale=y_scale),
                    tooltip=[
                        alt.Tooltip("date:T",  title="æ—¥ä»˜"),
                        alt.Tooltip("Close:Q", title="çµ‚å€¤", format=".2f"),
                        alt.Tooltip("Open:Q",  title="å§‹å€¤", format=".2f"),
                        alt.Tooltip("High:Q",  title="é«˜å€¤", format=".2f"),
                        alt.Tooltip("Low:Q",   title="å®‰å€¤", format=".2f"),
                    ],
                )
                .properties(height=260)
                .interactive()
            )
            st.altair_chart(line, use_container_width=True)
            change = (df["Close"][-1]-df["Close"][0]) / df["Close"][0] * 100
            st.caption(f"æœŸé–“: {len(df)}æœ¬, å§‹å€¤={df['Open'][0]:.2f}, çµ‚å€¤={df['Close'][-1]:.2f}, å¤‰åŒ–ç‡={change:+.2f}%")
        else:
            st.info("ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        # ---- é…å½“ ----
        st.subheader("ğŸ’´ é…å½“ï¼ˆç›´è¿‘1å¹´TTMï¼å‚è€ƒï¼‰")
        last_close = float(df["Close"][-1]) if not df.empty else 0.0
        div_info = get_dividend_info(code, last_close)

        if div_info["ttm_div"] is not None:
            yld = f"{div_info['yield_pct']:.2f}%" if div_info['yield_pct'] is not None else "â€”"
            st.write(f"TTMé…å½“åˆè¨ˆ: **{div_info['ttm_div']:.2f}** / å‚è€ƒåˆ©å›ã‚Š: **{yld}**ï¼ˆæ–¹æ³•: TTM 400æ—¥ï¼‰")
        elif div_info["alt_div"] is not None:
            alt_yld = f"{div_info['alt_yield']:.2f}%" if div_info['alt_yield'] is not None else "â€”"
            st.write(f"TTMé…å½“åˆè¨ˆ: â€” / ä»£æ›¿ï¼ˆç›´è¿‘æœ€å¤§2å›ã®åˆè¨ˆï¼‰: **{div_info['alt_div']:.2f}** / å‚è€ƒåˆ©å›ã‚Š: **{alt_yld}**")
        else:
            st.write("é…å½“ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        if not div_info["recent"].empty:
            st.dataframe(
                div_info["recent"].rename(columns={"date":"æ—¥ä»˜","dividend":"é…å½“(1æ ª)"}),
                use_container_width=True
            )

        # ---- æ ªä¸»å„ªå¾…ãƒªãƒ³ã‚¯ï¼ˆå‚è€ƒï¼‰----
        st.markdown(
            "ğŸ”— æ ªä¸»å„ªå¾…æƒ…å ±ã¯ä»¥ä¸‹ã®å¤–éƒ¨ã‚µã‚¤ãƒˆã§ç¢ºèªã§ãã¾ã™ï¼š\n"
            "[æ ªä¸»å„ªå¾…ã‚’æ¢ã™ï¼ˆkabuyutai.comï¼‰](https://www.kabuyutai.com/)"
        )

        # ---- ãƒ‹ãƒ¥ãƒ¼ã‚¹ ----
        st.subheader("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆGoogle News RSSï¼‰")
        news = fetch_news_for(code, alias_df=alias_df, days=30, max_items=8, strict_title=True, min_score=2)
        if news:
            for n in news:
                st.markdown(f"- [{n['title']}]({n['link']}) ã€”score={n['score']}ã€•")
        else:
            st.write("ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# ========= ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è¦æ±‚ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰ =========
if st.session_state.get("dl_alias"):
    st.info("ç¾åœ¨ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¡¨ï¼ˆxlsxï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
    download_current_alias_button(alias_df)
    st.session_state["dl_alias"] = False

# ========= ãƒ•ãƒƒã‚¿ãƒ¼ =========
st.caption("Powered by Streamlit / yfinance / Google News RSS / Google Sheets")
